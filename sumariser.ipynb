{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sumariser.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNScs6gO8QZi9KnrnA4ZEVs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Souravdey15/AI-Powered-Tech-support-platform/blob/master/sumariser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsCeLgUXGrl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9d0a21c1-f71f-4f8d-9ac0-ad75abe97129"
      },
      "source": [
        "import csv\n",
        "import datetime\n",
        "import spacy\n",
        "spacy.load('en_core_web_sm')\n",
        "import heapq\n",
        "import json\n",
        "import os.path\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from pprint import pprint\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from nltk import ne_chunk\n",
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from spacy import displacy\n",
        "from wordcloud import WordCloud\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsHImO9dG0hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('convotext.txt', 'r').read().lower()\n",
        "\n",
        "f = re.sub(r'\\s+', ' ', f)\n",
        "no_of_lines = len(open('convotext.txt', 'r').readlines())\n",
        "stop_words = set(\n",
        "    stopwords.words('english') +\n",
        "    ['i', 'he', 'me', 'she', 'it', 'them', 'her', 'him'])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWVDUEuXG-79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punc(sent):\n",
        "    #\n",
        "    punctuations = '''!()-[]{};'\"\\,<>/?@#%^&*_~'''\n",
        "    for x in sent:\n",
        "        if x in punctuations:\n",
        "            sent = sent.replace(x, \" \")\n",
        "    return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MFc1pVWHEwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sent):\n",
        "    #\n",
        "    sent = remove_punc(sent)\n",
        "    sent = nltk.word_tokenize(sent, language='english')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sent = [lemmatizer.lemmatize(x) for x in sent]\n",
        "    sent = ' '.join(sent)\n",
        "    filtered_sentence = [\n",
        "        w for w in sent.split(' ') if not w.lower() in stop_words\n",
        "    ]\n",
        "\n",
        "    return ' '.join(filtered_sentence).lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUROEEuwHJw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_freq(sent):\n",
        "    word_frequencies = {}\n",
        "    for word in sent:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "\n",
        "    maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "    for word in word_frequencies.keys():\n",
        "        word_frequencies[word] = (word_frequencies[word] / maximum_frequncy)\n",
        "\n",
        "    return word_frequencies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VtX4JB8HMyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_score_calc(text, word_frequencies):\n",
        "    sentence_list = nltk.sent_tokenize(text)\n",
        "    sentence_scores = {}\n",
        "    for sent in sentence_list:\n",
        "        for word in nltk.word_tokenize(sent.lower()):\n",
        "            if word in word_frequencies.keys():\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]\n",
        "    return sentence_scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO8VQ37bHRhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractive_summary(f, docu):\n",
        "    max_freq = weighted_freq(docu)\n",
        "    sent_scores = sent_score_calc(f, max_freq)\n",
        "    no_of_lines = len(docu.split('.'))\n",
        "    summary_sentences = heapq.nlargest(int(no_of_lines / 3),\n",
        "                                       sent_scores,\n",
        "                                       key=sent_scores.get)\n",
        "    #summary_sentences =sorted(sent_scores, key=sent_scores.get, reverse=True)[:int(no_of_lines/2)]  SUMMARY OF EACH LINE CAN BE GENERATED\n",
        "\n",
        "    summary = ' '.join(i.capitalize() for i in summary_sentences)\n",
        "    print(summary)\n",
        "    fileName = docu\n",
        "    return summary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRpMQvPFHU6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7460d9fd-07e8-4342-ec4e-d599732cb463"
      },
      "source": [
        "\" \".join(f.split(\"\\n\"))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"boss thank you all for coming today. first of all, i would like you all to meet mr. mark johnson. he is our new salesperson with the company. here is my number 9003401119 and my email id is sourav.lko@gmail.com i think mark has met everyone, oh, except for ann. hello, mark. i am ann nice to meet you. i am a salesperson, too. it's nice to meet you, ann maybe you can help to teach me about my new job. sure. we can be a .team you help me, i'll help you. that sounds good to me, too. now let's talk about business. linda, will you please take notes of our meeting for us? sure, i have my pen and paper ready. yes please book a meeting on tuesday 10pm. i want to book a flight on 10 june 2019. great. please read the notes of our last meeting for us. okay. first, we talked about the budget for next year. i will budget is getting smaller every year. second, we talked about the new products we are going to selling. she means the new products you and i will be selling. o.k. third, we talked about the profits that we had last month. and fourth, we talked about the bills we had to pay. we always have more bills than profits. finally, we talked about raising the cost of our new products. i'm afraid our customers will think our product is too expensive. why is everyone whispering? sorry, linda. o.k. we have a few things to talk about today. susan, would you like to give your report. yes, thank you. i have a sales graph i would like to show everyone. this shows how well we are selling our products this year. this line is the sales of our products. and this line is the sales of our competitors' products. so if that line goes up, am i doing a good job? exactly. o.k. and if that line goes up, does my salary go up? good question, ann. we'll talk about that after the meeting. susan, do we have many competitors? no, not really but enough to keep us busy. anyway, good job, ann. i'm sure you and mark will do even better next month! thank you, susan. very good. tom, do you have anything to tell everyone. yes. don't forget, if you want me to buy something for your office, the deadline is tomorrow. oh!! i need a new typewriter. mine is broken. o.k. no problem. if anyone wants me to buy something, tell me before the deadline. o.k. is that everything? o.k. i think that's all. you can go now. oh, wait!! mark has a presentation he would like to give about his new job. oh, yeah, o.k. \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKbcD1WSHZPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "122fd367-983c-455c-ba0d-71f62683e919"
      },
      "source": [
        "extractive_summary(\" \".join(f.split(\"\\n\")), docu=f)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O.k. I have a sales graph i would like to show everyone. I am a salesperson, too. We can be a .team you help me, i'll help you. I want to book a flight on 10 june 2019. great. I need a new typewriter. So if that line goes up, am i doing a good job? Here is my number 9003401119 and my email id is sourav.lko@gmail.com i think mark has met everyone, oh, except for ann. Yes please book a meeting on tuesday 10pm. We have a few things to talk about today. Mark has a presentation he would like to give about his new job. First of all, i would like you all to meet mr. mark johnson. Sure, i have my pen and paper ready. I am ann nice to meet you. I will budget is getting smaller every year. She means the new products you and i will be selling. I'm afraid our customers will think our product is too expensive. I think that's all. Anyway, good job, ann. Don't forget, if you want me to buy something for your office, the deadline is tomorrow. Oh, yeah, o.k. I'm sure you and mark will do even better next month! Hello, mark.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"O.k. I have a sales graph i would like to show everyone. I am a salesperson, too. We can be a .team you help me, i'll help you. I want to book a flight on 10 june 2019. great. I need a new typewriter. So if that line goes up, am i doing a good job? Here is my number 9003401119 and my email id is sourav.lko@gmail.com i think mark has met everyone, oh, except for ann. Yes please book a meeting on tuesday 10pm. We have a few things to talk about today. Mark has a presentation he would like to give about his new job. First of all, i would like you all to meet mr. mark johnson. Sure, i have my pen and paper ready. I am ann nice to meet you. I will budget is getting smaller every year. She means the new products you and i will be selling. I'm afraid our customers will think our product is too expensive. I think that's all. Anyway, good job, ann. Don't forget, if you want me to buy something for your office, the deadline is tomorrow. Oh, yeah, o.k. I'm sure you and mark will do even better next month! Hello, mark.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmtT22OIHfC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_train_gen():\n",
        "    # l = ['my no is 8874672257','is your phone 7903390453','your phone no is 8318788891','here is my no 9003387921','here is my no 9600644223']\n",
        "    l = [\n",
        "        \"my email is ~shivipandey11@gmail.com\",\n",
        "        \"is your email id ~rules@yahoo.com\",\n",
        "        \"your email is ~sourav@rediff.com\", \"here is email ~bcb@mail.com\",\n",
        "        \"here is email id ~hello@find.in\"\n",
        "    ]\n",
        "    s = ''\n",
        "    for a in l:\n",
        "        s += \"[({},{},'EMAIL')]\\n\".format(\n",
        "            re.search(r'~', a).start() + 1, len(a))\n",
        "    print(s)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-mnyk2jHkUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_sp_model():\n",
        "    TRAIN_DATA = [(u\"my no is 8874672257\", {\n",
        "        \"entities\": [(9, 19, \"PHONE\")]\n",
        "    }), (u\"is your phone 7903390453\", {\n",
        "        \"entities\": [(14, 24, \"PHONE\")]\n",
        "    }), (u\"your phone number is 8318788891\", {\n",
        "        \"entities\": [(17, 27, \"PHONE\")]\n",
        "    }), (u\"here is my no 9003387921\", {\n",
        "        \"entities\": [(14, 24, \"PHONE\")]\n",
        "    }), (u\"here is my number 9600644223\", {\n",
        "        \"entities\": [(14, 24, \"PHONE\")]\n",
        "    }),\n",
        "        (u\"my email is shivipandey11@gmail.com\", {\n",
        "            \"entities\": [(12, 34, \"EMAIL\")]\n",
        "        }),\n",
        "        (u\"is your email id rules@yahoo.com\", {\n",
        "            \"entities\": [(17, 33, \"EMAIL\")]\n",
        "        }),\n",
        "        (u\"your email is sourav@rediff.com\", {\n",
        "            \"entities\": [(14, 32, \"EMAIL\")]\n",
        "        }),\n",
        "        (u\"here is email bcb@mail.com\", {\n",
        "            \"entities\": [(14, 27, \"EMAIL\")]\n",
        "        }),\n",
        "        (u\"here my email id hello@find.in\", {\n",
        "            \"entities\": [(17, 31, \"EMAIL\")]\n",
        "        })]\n",
        "    nlp = spacy.blank('en')\n",
        "    \"\"\"optimizer = nlp.begin_training()\n",
        "    for i in range(20):\n",
        "         random.shuffle(TRAIN_DATA)\n",
        "         for text, annotations in TRAIN_DATA:\n",
        "             nlp.update([text], [annotations], sgd=optimizer)\n",
        "    \"\"\" #TO Optimize the summarizer depending upon the needs of the buisness partners\n",
        "    batches = spacy.util.minibatch(TRAIN_DATA)\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(texts, annotations)\n",
        "    nlp.to_disk(\"newmod\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX2Z3oX8Hqep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_context(docu):\n",
        "\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc = nlp(docu)\n",
        "    fin_dic = {}\n",
        "    for ent in doc.ents:\n",
        "        fin_dic[ent.text] = ent.label_\n",
        "    return json.dumps(fin_dic, sort_keys=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EoN0SDrHued",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def context_json(p):\n",
        "    dic = json.loads(return_context(p))\n",
        "    d_final = {'persons': [], 'phone': [], 'emails': [], 'date': []}\n",
        "    d_final['phone'].extend(re.findall(r'\\d{10}', p))\n",
        "    d_final['emails'].extend(re.findall(r'\\S+@\\S+', p))\n",
        "\n",
        "    for a in dic:\n",
        "        if dic[a] == 'PERSON':\n",
        "            d_final['persons'].append(a)\n",
        "        if dic[a] == 'DATE':\n",
        "            d_final['date'].append(a)\n",
        "    l = []\n",
        "    for a in d_final:\n",
        "        l.append(d_final[a])\n",
        "\n",
        "    pd.DataFrame({k: pd.Series(l) for k, l in d_final.items()}).to_csv('output.csv',columns = ['persons','phone','emails','date'])\n",
        "    # print(json.dumps(d_final))\n",
        "    return json.dumps(d_final)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3MPrvhXIrzH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFakh29hHzGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4097cab6-f81d-474d-c62c-73068fd22175"
      },
      "source": [
        "context_json(f)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"persons\": [\"ann\", \"ann nice\", \"linda\", \"mark\", \"mark johnson\", \"susan\", \"tom\"], \"phone\": [\"9003401119\"], \"emails\": [\"sourav.lko@gmail.com\"], \"date\": [\"10 june 2019\", \"every year\", \"last month\", \"next month\", \"next year\", \"this year\", \"today\", \"tomorrow\", \"tuesday 10pm\"]}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFgXk9I_H1f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}